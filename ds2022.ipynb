{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers fuckit seqeval nlpaug sacremoses TelegramBotAPI\n!pip install pyTelegramBotAPI","metadata":{"id":"-plN9RPFPqpr","outputId":"708e6e59-f8f1-42d9-bdf7-6e1109c2f5e2","execution":{"iopub.status.busy":"2023-02-10T10:25:06.594431Z","iopub.execute_input":"2023-02-10T10:25:06.594894Z","iopub.status.idle":"2023-02-10T10:25:39.165308Z","shell.execute_reply.started":"2023-02-10T10:25:06.594810Z","shell.execute_reply":"2023-02-10T10:25:39.164169Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting pyTelegramBotAPI\n  Downloading pyTelegramBotAPI-4.10.0.tar.gz (222 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.9/222.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pyTelegramBotAPI) (2.28.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pyTelegramBotAPI) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->pyTelegramBotAPI) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->pyTelegramBotAPI) (1.26.13)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pyTelegramBotAPI) (2022.12.7)\nBuilding wheels for collected packages: pyTelegramBotAPI\n  Building wheel for pyTelegramBotAPI (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyTelegramBotAPI: filename=pyTelegramBotAPI-4.10.0-py3-none-any.whl size=205420 sha256=3530436f9f7f0f7b49dcf732494fe788c54156fb8bf58213b0cd8940cb6db959\n  Stored in directory: /root/.cache/pip/wheels/70/e4/10/69f970d610fe598d0b2d78b3f373c22375fedce8a3145d3220\nSuccessfully built pyTelegramBotAPI\nInstalling collected packages: pyTelegramBotAPI\nSuccessfully installed pyTelegramBotAPI-4.10.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/baochi0212/data-science-e10","metadata":{"id":"SUHKYDk8PHa3","outputId":"be298e6d-93c3-4cab-a6a2-2a1dc963a648","execution":{"iopub.status.busy":"2023-02-10T10:25:39.167861Z","iopub.execute_input":"2023-02-10T10:25:39.168245Z","iopub.status.idle":"2023-02-10T10:25:42.640706Z","shell.execute_reply.started":"2023-02-10T10:25:39.168207Z","shell.execute_reply":"2023-02-10T10:25:42.639520Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'data-science-e10'...\nremote: Enumerating objects: 5517, done.\u001b[K\nremote: Counting objects: 100% (730/730), done.\u001b[K\nremote: Compressing objects: 100% (230/230), done.\u001b[K\nremote: Total 5517 (delta 544), reused 681 (delta 499), pack-reused 4787\u001b[K\nReceiving objects: 100% (5517/5517), 29.14 MiB | 24.32 MiB/s, done.\nResolving deltas: 100% (2129/2129), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%env BOT_TOKEN=5891233815:AAEcILTmQopcK9K3Sw1dayqRBguCBBa_RLk","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:25:42.642814Z","iopub.execute_input":"2023-02-10T10:25:42.643218Z","iopub.status.idle":"2023-02-10T10:25:42.650082Z","shell.execute_reply.started":"2023-02-10T10:25:42.643180Z","shell.execute_reply":"2023-02-10T10:25:42.649118Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"env: BOT_TOKEN=5891233815:AAEcILTmQopcK9K3Sw1dayqRBguCBBa_RLk\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd  data-science-e10","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:25:42.652812Z","iopub.execute_input":"2023-02-10T10:25:42.653543Z","iopub.status.idle":"2023-02-10T10:25:42.663240Z","shell.execute_reply.started":"2023-02-10T10:25:42.653507Z","shell.execute_reply":"2023-02-10T10:25:42.662246Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/data-science-e10\n","output_type":"stream"}]},{"cell_type":"code","source":"# %cd data-science-e10/source/active-learning","metadata":{"id":"UcnTl7_YPbP4","outputId":"bbbb0bff-13b2-40ba-f5f2-7a290bde5a81","execution":{"iopub.status.busy":"2023-01-31T16:38:39.626960Z","iopub.execute_input":"2023-01-31T16:38:39.627438Z","iopub.status.idle":"2023-01-31T16:38:39.659066Z","shell.execute_reply.started":"2023-01-31T16:38:39.627340Z","shell.execute_reply":"2023-01-31T16:38:39.658082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !git pull ","metadata":{"id":"0OrnICKWQZMM","outputId":"c3a865db-f17b-4b4c-905e-088c2dc2d9e8","execution":{"iopub.status.busy":"2023-02-03T09:24:38.149177Z","iopub.execute_input":"2023-02-03T09:24:38.149572Z","iopub.status.idle":"2023-02-03T09:24:39.965707Z","shell.execute_reply.started":"2023-02-03T09:24:38.149535Z","shell.execute_reply":"2023-02-03T09:24:39.964584Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Already up to date.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ACTIVE LEARNING","metadata":{}},{"cell_type":"markdown","source":"## randomsampling","metadata":{}},{"cell_type":"code","source":"# !python demo.py --dataset sensitive --dataset_name sensitive --method ce --n_init_labeled 250 --n_query 150 --n_round 8 --num_epoch 10  --strategy_name RandomSampling #logger + collate_fn","metadata":{"id":"g-xTx1cUPery","outputId":"bcde4048-11da-4999-f18d-bed029b03c3d","execution":{"iopub.status.busy":"2023-01-14T01:35:46.713233Z","iopub.execute_input":"2023-01-14T01:35:46.713635Z","iopub.status.idle":"2023-01-14T02:03:14.060645Z","shell.execute_reply.started":"2023-01-14T01:35:46.713600Z","shell.execute_reply":"2023-01-14T02:03:14.059470Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## least confidence","metadata":{}},{"cell_type":"code","source":"# !python demo.py --dataset sensitive --dataset_name sensitive --method ce --n_init_labeled 250 --n_query 150 --n_round 8 --num_epoch 10  --strategy_name LeastConfidence #logger + collate_fn","metadata":{"id":"bkMkpveIPitR","outputId":"6c051737-8f1b-4fb3-cf74-ba51f86db831","execution":{"iopub.status.busy":"2023-01-15T14:17:56.450092Z","iopub.execute_input":"2023-01-15T14:17:56.450441Z","iopub.status.idle":"2023-01-15T14:47:27.101212Z","shell.execute_reply.started":"2023-01-15T14:17:56.450402Z","shell.execute_reply":"2023-01-15T14:47:27.100032Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## highest entropy ","metadata":{}},{"cell_type":"code","source":"# !python demo.py --dataset sensitive --dataset_name sensitive --method ce --n_init_labeled 250 --n_query 150 --n_round 8 --num_epoch 10  --strategy_name EntropySampling #logger + collate_fn","metadata":{"id":"UYkXZ0Q5wwWi","execution":{"iopub.status.busy":"2023-01-14T02:32:37.707040Z","iopub.execute_input":"2023-01-14T02:32:37.707451Z","iopub.status.idle":"2023-01-14T03:02:03.478796Z","shell.execute_reply.started":"2023-01-14T02:32:37.707408Z","shell.execute_reply":"2023-01-14T03:02:03.477603Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MAIN","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/data-science-e10/source","metadata":{"execution":{"iopub.status.busy":"2023-02-01T14:18:35.675396Z","iopub.execute_input":"2023-02-01T14:18:35.675794Z","iopub.status.idle":"2023-02-01T14:18:35.684283Z","shell.execute_reply.started":"2023-02-01T14:18:35.675751Z","shell.execute_reply":"2023-02-01T14:18:35.683179Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working/data-science-e10/source\n","output_type":"stream"}]},{"cell_type":"code","source":"!curl \"https://www.kaggleusercontent.com/kf/117884579/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..yNMEm8fq559ETxgiRpNJaQ.epDn8-1bcNrZaV7AvlRr4FMJglEmoEm_x6GhOLgyOOEXkmxxtyONZFYBon0IJEOAQxvFV99qBNyG_LOF0nHCH8j9MLksS8e_hTUSvFyQc7CP20q3kQoya4gxgKdELk9hWQTu-svvtHom68hnzlp1b6JyNN1SrkZ2_kgBSaPWQuPUCYQq61ExE10Z8LJSSAtb6pIWznLLbtuShCqEcG8l-4sgBt3XN6zNawlmx9rtAXT9aEZPBiEW2Xt3eEyQ1sIiiaQHsYX0ILmkhkhKfgHf0o3V5VKb6CU9wZ5WP9_g-3XEZjXz8oGzSgXUFrVNyNI8VA8ALD_i6NtuQGZtFjZcFIEbkKldQpv9ACp9710G-oUu39gy1I7V1OFrmWVPV0T2p1ZoVH_kipBEBORkbIoJKC1TjhVW49PJZHfRejRp-GPoidctKFkKnx0uHYXmBUG3aDR2Nj4tXdn9-4BHR16KJvvCrk8m2B9WaA4VeLAmltNrliHWmcURvISJ_Grv2TtHHrqDY4UPqFMY81LO6xnNzrcL5OX_swVCxYsMtkwLy2MbPmIP3JISLJR0ty9CF4BjfGgfrSziiNz6LctBr2FICkLVEu9fXcsgmU1wF4LMMBUgQFJu5KmqHUC9bOYcyHh95KkHdoBJxYY5S06GIVJEXg.MoITMTUnPwRpKGAyZbf9Wg/data-science-e10/source/data/sensitive_augment.json\" -o data/sensitive_temp.json","metadata":{"execution":{"iopub.status.busy":"2023-02-01T14:18:35.690232Z","iopub.execute_input":"2023-02-01T14:18:35.690648Z","iopub.status.idle":"2023-02-01T14:18:38.233172Z","shell.execute_reply.started":"2023-02-01T14:18:35.690613Z","shell.execute_reply":"2023-02-01T14:18:38.231993Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  760k  100  760k    0     0   490k      0  0:00:01  0:00:01 --:--:--  490k\n","output_type":"stream"}]},{"cell_type":"code","source":"!mv data/sensitive_train.json data/temp.json\n!mv data/sensitive_temp.json data/sensitive_train.json\n!mv data/temp.json data/sensitive_temp.json","metadata":{"execution":{"iopub.status.busy":"2023-02-01T14:45:29.622148Z","iopub.execute_input":"2023-02-01T14:45:29.622910Z","iopub.status.idle":"2023-02-01T14:45:32.457904Z","shell.execute_reply.started":"2023-02-01T14:45:29.622870Z","shell.execute_reply":"2023-02-01T14:45:32.456481Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import json \nfile = 'data/sensitive_temp.json'\nlen(json.load(open(file, 'r')))","metadata":{"execution":{"iopub.status.busy":"2023-02-01T14:45:34.057971Z","iopub.execute_input":"2023-02-01T14:45:34.059072Z","iopub.status.idle":"2023-02-01T14:45:34.079001Z","shell.execute_reply.started":"2023-02-01T14:45:34.059023Z","shell.execute_reply":"2023-02-01T14:45:34.077990Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"3097"},"metadata":{}}]},{"cell_type":"code","source":"!python main.py --dataset sensitive --method ce --lr 5e-6  --model_name bert --num_epoch 15 --alpha 0.5 --train_batch_size 32","metadata":{"execution":{"iopub.status.busy":"2023-02-01T14:45:36.033410Z","iopub.execute_input":"2023-02-01T14:45:36.034256Z","iopub.status.idle":"2023-02-01T14:53:38.686909Z","shell.execute_reply.started":"2023-02-01T14:45:36.034216Z","shell.execute_reply":"2023-02-01T14:53:38.685669Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"> creating model bert\n> cuda memory allocated: 439085568\n> training arguments:\n>>> data_dir: data\n>>> dataset: sensitive\n>>> model_name: bert\n>>> method: ce\n>>> train_batch_size: 32\n>>> test_batch_size: 64\n>>> num_epoch: 15\n>>> lr: 5e-06\n>>> decay: 0.01\n>>> alpha: 0.5\n>>> temp: 0.1\n>>> backend: False\n>>> timestamp: 1675262741497\n>>> device: cuda\n>>> num_classes: 5\n>>> log_name: sensitive_bert_ce_23-02-01_14-45-41.log\n100%|===========================================| 48/48 [00:24<00:00,  1.93it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.82it/s]\n              precision    recall  f1-score   support\n\n           0       0.84      0.79      0.82       205\n           1       0.64      0.14      0.24       159\n           2       0.65      0.94      0.77       211\n           3       0.77      0.27      0.40       174\n           4       0.49      0.76      0.59       270\n\n    accuracy                           0.62      1019\n   macro avg       0.68      0.58      0.56      1019\nweighted avg       0.66      0.62      0.59      1019\n\n1/15 - 6.67%\n[train] loss: 1.5352, acc: 32.96\n[test] loss: 1.2731, acc: 62.41\n100%|===========================================| 48/48 [00:24<00:00,  1.92it/s]\n100%|===========================================| 16/16 [00:05<00:00,  3.11it/s]\n              precision    recall  f1-score   support\n\n           0       0.98      0.85      0.91       205\n           1       0.78      0.71      0.74       159\n           2       0.77      0.97      0.86       211\n           3       0.65      0.60      0.62       174\n           4       0.65      0.65      0.65       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.76      0.76      1019\nweighted avg       0.76      0.76      0.76      1019\n\n2/15 - 13.33%\n[train] loss: 0.9589, acc: 71.15\n[test] loss: 0.7872, acc: 75.86\n100%|===========================================| 48/48 [00:25<00:00,  1.87it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.88it/s]\n              precision    recall  f1-score   support\n\n           0       0.99      0.87      0.93       205\n           1       0.83      0.77      0.80       159\n           2       0.77      0.97      0.86       211\n           3       0.60      0.64      0.62       174\n           4       0.68      0.61      0.64       270\n\n    accuracy                           0.77      1019\n   macro avg       0.78      0.77      0.77      1019\nweighted avg       0.77      0.77      0.77      1019\n\n3/15 - 20.00%\n[train] loss: 0.5443, acc: 86.16\n[test] loss: 0.6685, acc: 76.64\n100%|===========================================| 48/48 [00:25<00:00,  1.88it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.92it/s]\n              precision    recall  f1-score   support\n\n           0       1.00      0.84      0.91       205\n           1       0.83      0.82      0.83       159\n           2       0.78      0.97      0.86       211\n           3       0.58      0.66      0.62       174\n           4       0.69      0.58      0.63       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.77      0.77      1019\nweighted avg       0.77      0.76      0.76      1019\n\n4/15 - 26.67%\n[train] loss: 0.3793, acc: 89.43\n[test] loss: 0.6618, acc: 76.45\n100%|===========================================| 48/48 [00:25<00:00,  1.91it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.74it/s]\n              precision    recall  f1-score   support\n\n           0       1.00      0.81      0.90       205\n           1       0.87      0.82      0.85       159\n           2       0.80      0.97      0.87       211\n           3       0.56      0.69      0.62       174\n           4       0.68      0.59      0.63       270\n\n    accuracy                           0.77      1019\n   macro avg       0.78      0.78      0.77      1019\nweighted avg       0.78      0.77      0.77      1019\n\n5/15 - 33.33%\n[train] loss: 0.3019, acc: 91.64\n[test] loss: 0.6898, acc: 76.64\n100%|===========================================| 48/48 [00:24<00:00,  1.96it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.89it/s]\n              precision    recall  f1-score   support\n\n           0       1.00      0.83      0.91       205\n           1       0.83      0.82      0.82       159\n           2       0.79      0.97      0.87       211\n           3       0.56      0.67      0.61       174\n           4       0.68      0.57      0.62       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.77      0.76      1019\nweighted avg       0.77      0.76      0.76      1019\n\n6/15 - 40.00%\n[train] loss: 0.2485, acc: 92.62\n[test] loss: 0.7069, acc: 75.86\n100%|===========================================| 48/48 [00:24<00:00,  1.94it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.85it/s]\n              precision    recall  f1-score   support\n\n           0       1.00      0.82      0.90       205\n           1       0.86      0.81      0.83       159\n           2       0.79      0.97      0.87       211\n           3       0.59      0.67      0.62       174\n           4       0.68      0.62      0.65       270\n\n    accuracy                           0.77      1019\n   macro avg       0.78      0.78      0.78      1019\nweighted avg       0.78      0.77      0.77      1019\n\n7/15 - 46.67%\n[train] loss: 0.2220, acc: 93.67\n[test] loss: 0.7086, acc: 76.94\n100%|===========================================| 48/48 [00:24<00:00,  1.93it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.80it/s]\n              precision    recall  f1-score   support\n\n           0       1.00      0.83      0.91       205\n           1       0.81      0.82      0.82       159\n           2       0.80      0.97      0.87       211\n           3       0.56      0.68      0.61       174\n           4       0.67      0.55      0.61       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.77      0.76      1019\nweighted avg       0.77      0.76      0.76      1019\n\n8/15 - 53.33%\n[train] loss: 0.2043, acc: 94.26\n[test] loss: 0.7344, acc: 75.76\n100%|===========================================| 48/48 [00:24<00:00,  1.97it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.70it/s]\n              precision    recall  f1-score   support\n\n           0       1.00      0.85      0.92       205\n           1       0.81      0.81      0.81       159\n           2       0.80      0.97      0.88       211\n           3       0.56      0.68      0.62       174\n           4       0.68      0.55      0.61       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.77      0.77      1019\nweighted avg       0.77      0.76      0.76      1019\n\n9/15 - 60.00%\n[train] loss: 0.1749, acc: 95.43\n[test] loss: 0.7389, acc: 76.05\n100%|===========================================| 48/48 [00:24<00:00,  1.92it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.95it/s]\n              precision    recall  f1-score   support\n\n           0       1.00      0.84      0.92       205\n           1       0.81      0.81      0.81       159\n           2       0.80      0.97      0.88       211\n           3       0.56      0.68      0.61       174\n           4       0.67      0.54      0.60       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.77      0.76      1019\nweighted avg       0.77      0.76      0.76      1019\n\n10/15 - 66.67%\n[train] loss: 0.1653, acc: 95.04\n[test] loss: 0.7629, acc: 75.66\n100%|===========================================| 48/48 [00:24<00:00,  1.93it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.99it/s]\n              precision    recall  f1-score   support\n\n           0       1.00      0.83      0.91       205\n           1       0.81      0.80      0.80       159\n           2       0.80      0.97      0.88       211\n           3       0.56      0.68      0.62       174\n           4       0.66      0.56      0.60       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.77      0.76      1019\nweighted avg       0.77      0.76      0.75      1019\n\n11/15 - 73.33%\n[train] loss: 0.1526, acc: 95.95\n[test] loss: 0.7698, acc: 75.56\n100%|===========================================| 48/48 [00:25<00:00,  1.91it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.86it/s]\n              precision    recall  f1-score   support\n\n           0       1.00      0.85      0.92       205\n           1       0.81      0.81      0.81       159\n           2       0.80      0.97      0.88       211\n           3       0.56      0.68      0.61       174\n           4       0.68      0.54      0.60       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.77      0.76      1019\nweighted avg       0.77      0.76      0.76      1019\n\n12/15 - 80.00%\n[train] loss: 0.1457, acc: 96.15\n[test] loss: 0.7811, acc: 75.86\n100%|===========================================| 48/48 [00:25<00:00,  1.92it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.75it/s]\n              precision    recall  f1-score   support\n\n           0       1.00      0.84      0.91       205\n           1       0.80      0.81      0.80       159\n           2       0.80      0.97      0.88       211\n           3       0.56      0.68      0.62       174\n           4       0.67      0.55      0.60       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.77      0.76      1019\nweighted avg       0.77      0.76      0.76      1019\n\n13/15 - 86.67%\n[train] loss: 0.1372, acc: 96.54\n[test] loss: 0.7891, acc: 75.66\n100%|===========================================| 48/48 [00:25<00:00,  1.91it/s]\n100%|===========================================| 16/16 [00:05<00:00,  3.04it/s]\n              precision    recall  f1-score   support\n\n           0       1.00      0.85      0.92       205\n           1       0.80      0.82      0.81       159\n           2       0.80      0.97      0.88       211\n           3       0.56      0.69      0.62       174\n           4       0.68      0.54      0.61       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.77      0.77      1019\nweighted avg       0.77      0.76      0.76      1019\n\n14/15 - 93.33%\n[train] loss: 0.1274, acc: 96.74\n[test] loss: 0.7945, acc: 76.05\n100%|===========================================| 48/48 [00:24<00:00,  1.93it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.89it/s]\n              precision    recall  f1-score   support\n\n           0       1.00      0.84      0.92       205\n           1       0.80      0.82      0.81       159\n           2       0.80      0.97      0.88       211\n           3       0.56      0.69      0.62       174\n           4       0.68      0.54      0.60       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.77      0.77      1019\nweighted avg       0.77      0.76      0.76      1019\n\n15/15 - 100.00%\n[train] loss: 0.1224, acc: 96.67\n[test] loss: 0.7991, acc: 75.96\nbest loss: 0.7086, best acc: 76.94\nlog saved: sensitive_bert_ce_23-02-01_14-45-41.log\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# AUGMENTATION","metadata":{}},{"cell_type":"code","source":"!git pull","metadata":{"execution":{"iopub.status.busy":"2023-01-31T16:07:46.658798Z","iopub.execute_input":"2023-01-31T16:07:46.659202Z","iopub.status.idle":"2023-01-31T16:07:48.227612Z","shell.execute_reply.started":"2023-01-31T16:07:46.659167Z","shell.execute_reply":"2023-01-31T16:07:48.226460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env MAIN_DIR=/kaggle/working/data-science-e10\n%cd /kaggle/working/data-science-e10/source","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:49:40.911570Z","iopub.execute_input":"2023-01-31T15:49:40.911953Z","iopub.status.idle":"2023-01-31T15:49:40.922756Z","shell.execute_reply.started":"2023-01-31T15:49:40.911920Z","shell.execute_reply":"2023-01-31T15:49:40.921454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python augment.py","metadata":{"execution":{"iopub.status.busy":"2023-01-31T16:07:50.224424Z","iopub.execute_input":"2023-01-31T16:07:50.224799Z","iopub.status.idle":"2023-01-31T16:37:53.488486Z","shell.execute_reply.started":"2023-01-31T16:07:50.224765Z","shell.execute_reply":"2023-01-31T16:37:53.487310Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/facebookresearch/DPR.git \n%cd DPR\n!pip install . #turn on and then restart","metadata":{"execution":{"iopub.status.busy":"2023-02-01T16:00:06.009472Z","iopub.execute_input":"2023-02-01T16:00:06.009763Z","iopub.status.idle":"2023-02-01T16:00:30.750762Z","shell.execute_reply.started":"2023-02-01T16:00:06.009703Z","shell.execute_reply":"2023-02-01T16:00:30.749609Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'DPR'...\nremote: Enumerating objects: 1195, done.\u001b[K\nremote: Counting objects: 100% (726/726), done.\u001b[K\nremote: Compressing objects: 100% (231/231), done.\u001b[K\nremote: Total 1195 (delta 564), reused 582 (delta 491), pack-reused 469\u001b[K\nReceiving objects: 100% (1195/1195), 520.26 KiB | 749.00 KiB/s, done.\nResolving deltas: 100% (796/796), done.\n/kaggle/working/DPR\nProcessing /kaggle/working/DPR\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting faiss-cpu>=1.6.1\n  Downloading faiss_cpu-1.7.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from dpr==1.0.0) (3.7.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from dpr==1.0.0) (1.21.6)\nRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from dpr==1.0.0) (2021.11.10)\nRequirement already satisfied: torch>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from dpr==1.0.0) (1.11.0)\nRequirement already satisfied: transformers>=4.3 in /opt/conda/lib/python3.7/site-packages (from dpr==1.0.0) (4.20.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from dpr==1.0.0) (4.64.0)\nCollecting wget\n  Downloading wget-3.2.zip (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: spacy>=2.1.8 in /opt/conda/lib/python3.7/site-packages (from dpr==1.0.0) (3.3.2)\nCollecting hydra-core>=1.0.0\n  Downloading hydra_core-1.3.1-py3-none-any.whl (154 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting omegaconf>=2.0.1\n  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: jsonlines in /opt/conda/lib/python3.7/site-packages (from dpr==1.0.0) (1.2.0)\nRequirement already satisfied: soundfile in /opt/conda/lib/python3.7/site-packages (from dpr==1.0.0) (0.11.0)\nCollecting editdistance\n  Downloading editdistance-0.6.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.6/282.6 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from hydra-core>=1.0.0->dpr==1.0.0) (5.10.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from hydra-core>=1.0.0->dpr==1.0.0) (22.0)\nRequirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.7/site-packages (from omegaconf>=2.0.1->dpr==1.0.0) (6.0)\nRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (0.10.1)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (0.4.2)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (1.8.2)\nRequirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (8.0.17)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (2.0.8)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (2.4.5)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (1.0.4)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (6.3.0)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (2.0.7)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (0.10.1)\nRequirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (4.1.1)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (1.0.9)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (0.7.9)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (3.0.8)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (3.0.11)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (59.8.0)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (2.28.1)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (3.3.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.1.8->dpr==1.0.0) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.3->dpr==1.0.0) (0.10.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.3->dpr==1.0.0) (4.13.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.3->dpr==1.0.0) (0.12.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from jsonlines->dpr==1.0.0) (1.15.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.7/site-packages (from soundfile->dpr==1.0.0) (1.15.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy>=2.1.8->dpr==1.0.0) (3.8.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0->soundfile->dpr==1.0.0) (2.21)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.8->dpr==1.0.0) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.8->dpr==1.0.0) (1.26.13)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.8->dpr==1.0.0) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.8->dpr==1.0.0) (2022.12.7)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy>=2.1.8->dpr==1.0.0) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy>=2.1.8->dpr==1.0.0) (2.1.1)\nBuilding wheels for collected packages: dpr, antlr4-python3-runtime, wget\n  Building wheel for dpr (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for dpr: filename=dpr-1.0.0-py3-none-any.whl size=14215 sha256=774296c24def707dc2dc669d22b311896be3d041c105b36c71cbd33da68cc26f\n  Stored in directory: /tmp/pip-ephem-wheel-cache-0p9al5j0/wheels/0d/90/6b/9b59cbb12e5b7e53f8afc55e6389e2478e2015e4ad85a6e428\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=86490a6a79b554ac7a82d0169a05b6aaee5f7e36ddc3d70fd56928860ffc884d\n  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n  Building wheel for wget (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=abc4ff140a7c0e931008cfc732e41985482e1807749f2cac7025ea835a40133c\n  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\nSuccessfully built dpr antlr4-python3-runtime wget\nInstalling collected packages: wget, faiss-cpu, antlr4-python3-runtime, omegaconf, editdistance, hydra-core, dpr\nSuccessfully installed antlr4-python3-runtime-4.9.3 dpr-1.0.0 editdistance-0.6.2 faiss-cpu-1.7.3 hydra-core-1.3.1 omegaconf-2.3.0 wget-3.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir save_data\n!mkdir save_data/downloads save_data/models\n!python /content/DPR/dprdata/download_data.py --resource data.retriever ","metadata":{"execution":{"iopub.status.busy":"2023-02-01T16:06:37.089481Z","iopub.execute_input":"2023-02-01T16:06:37.089874Z","iopub.status.idle":"2023-02-01T16:06:40.094251Z","shell.execute_reply.started":"2023-02-01T16:06:37.089841Z","shell.execute_reply":"2023-02-01T16:06:40.093084Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"python: can't open file '/content/DPR/dpr/data/download_data.py': [Errno 2] No such file or directory\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# SAVE and DEPLOY","metadata":{}},{"cell_type":"code","source":"%env SAVE_MODEL=/kaggle/working/data-science-e10/save_model","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:25:42.665006Z","iopub.execute_input":"2023-02-10T10:25:42.665474Z","iopub.status.idle":"2023-02-10T10:25:42.675811Z","shell.execute_reply.started":"2023-02-10T10:25:42.665334Z","shell.execute_reply":"2023-02-10T10:25:42.674536Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"env: SAVE_MODEL=/kaggle/working/data-science-e10/save_model\n","output_type":"stream"}]},{"cell_type":"code","source":"!git pull","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:25:42.677353Z","iopub.execute_input":"2023-02-10T10:25:42.677759Z","iopub.status.idle":"2023-02-10T10:25:44.105773Z","shell.execute_reply.started":"2023-02-10T10:25:42.677721Z","shell.execute_reply":"2023-02-10T10:25:44.104614Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Already up to date.\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir save_model","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:25:44.107377Z","iopub.execute_input":"2023-02-10T10:25:44.107749Z","iopub.status.idle":"2023-02-10T10:25:45.048425Z","shell.execute_reply.started":"2023-02-10T10:25:44.107715Z","shell.execute_reply":"2023-02-10T10:25:45.047091Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"%cd source","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:25:45.050205Z","iopub.execute_input":"2023-02-10T10:25:45.050862Z","iopub.status.idle":"2023-02-10T10:25:45.059405Z","shell.execute_reply.started":"2023-02-10T10:25:45.050815Z","shell.execute_reply":"2023-02-10T10:25:45.058442Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/kaggle/working/data-science-e10/source\n","output_type":"stream"}]},{"cell_type":"code","source":"!python main.py --dataset sensitive --method ce --lr 5e-6  --model_name bert --num_epoch 10 --alpha 0.5 --train_batch_size 32","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:27:57.341164Z","iopub.execute_input":"2023-02-10T10:27:57.341546Z","iopub.status.idle":"2023-02-10T10:33:27.536825Z","shell.execute_reply.started":"2023-02-10T10:27:57.341510Z","shell.execute_reply":"2023-02-10T10:33:27.535542Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"> creating model bert\n> cuda memory allocated: 439085568\n> training arguments:\n>>> data_dir: data\n>>> dataset: sensitive\n>>> model_name: bert\n>>> method: ce\n>>> train_batch_size: 32\n>>> test_batch_size: 64\n>>> num_epoch: 10\n>>> lr: 5e-06\n>>> decay: 0.01\n>>> alpha: 0.5\n>>> temp: 0.1\n>>> backend: False\n>>> timestamp: 1676024883176\n>>> device: cuda\n>>> num_classes: 5\n>>> log_name: sensitive_bert_ce_23-02-10_10-28-02.log\n100%|===========================================| 48/48 [00:25<00:00,  1.86it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.79it/s]\n              precision    recall  f1-score   support\n\n           0       0.84      0.55      0.67       205\n           1       0.69      0.25      0.37       159\n           2       0.53      0.92      0.68       211\n           3       0.75      0.05      0.10       174\n           4       0.40      0.67      0.51       270\n\n    accuracy                           0.53      1019\n   macro avg       0.64      0.49      0.46      1019\nweighted avg       0.62      0.53      0.48      1019\n\nBETTER MODEL SAVED\n1/10 - 10.00%\n[train] loss: 1.5713, acc: 28.85\n[test] loss: 1.3640, acc: 52.89\n100%|===========================================| 48/48 [00:24<00:00,  1.95it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.91it/s]\n              precision    recall  f1-score   support\n\n           0       0.99      0.73      0.84       205\n           1       0.79      0.70      0.74       159\n           2       0.74      0.95      0.83       211\n           3       0.66      0.61      0.63       174\n           4       0.59      0.64      0.61       270\n\n    accuracy                           0.73      1019\n   macro avg       0.75      0.73      0.73      1019\nweighted avg       0.74      0.73      0.73      1019\n\nBETTER MODEL SAVED\n2/10 - 20.00%\n[train] loss: 1.0131, acc: 68.73\n[test] loss: 0.8506, acc: 72.62\n100%|===========================================| 48/48 [00:24<00:00,  1.93it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.82it/s]\n              precision    recall  f1-score   support\n\n           0       0.99      0.80      0.89       205\n           1       0.85      0.75      0.80       159\n           2       0.78      0.96      0.86       211\n           3       0.56      0.68      0.61       174\n           4       0.62      0.56      0.58       270\n\n    accuracy                           0.74      1019\n   macro avg       0.76      0.75      0.75      1019\nweighted avg       0.75      0.74      0.74      1019\n\nBETTER MODEL SAVED\n3/10 - 30.00%\n[train] loss: 0.5642, acc: 84.60\n[test] loss: 0.7248, acc: 73.99\n100%|===========================================| 48/48 [00:25<00:00,  1.90it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.75it/s]\n              precision    recall  f1-score   support\n\n           0       0.99      0.81      0.90       205\n           1       0.88      0.77      0.82       159\n           2       0.79      0.95      0.87       211\n           3       0.55      0.70      0.61       174\n           4       0.64      0.56      0.60       270\n\n    accuracy                           0.75      1019\n   macro avg       0.77      0.76      0.76      1019\nweighted avg       0.76      0.75      0.75      1019\n\nBETTER MODEL SAVED\n4/10 - 40.00%\n[train] loss: 0.4104, acc: 87.34\n[test] loss: 0.7106, acc: 74.88\n100%|===========================================| 48/48 [00:25<00:00,  1.90it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.99it/s]\n              precision    recall  f1-score   support\n\n           0       0.99      0.81      0.90       205\n           1       0.85      0.79      0.82       159\n           2       0.79      0.96      0.87       211\n           3       0.55      0.68      0.61       174\n           4       0.66      0.56      0.60       270\n\n    accuracy                           0.75      1019\n   macro avg       0.77      0.76      0.76      1019\nweighted avg       0.76      0.75      0.75      1019\n\nBETTER MODEL SAVED\n5/10 - 50.00%\n[train] loss: 0.3285, acc: 90.27\n[test] loss: 0.7217, acc: 74.98\n100%|===========================================| 48/48 [00:24<00:00,  1.92it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.87it/s]\n              precision    recall  f1-score   support\n\n           0       0.99      0.81      0.90       205\n           1       0.86      0.80      0.83       159\n           2       0.78      0.96      0.86       211\n           3       0.55      0.69      0.61       174\n           4       0.66      0.55      0.60       270\n\n    accuracy                           0.75      1019\n   macro avg       0.77      0.76      0.76      1019\nweighted avg       0.77      0.75      0.75      1019\n\nBETTER MODEL SAVED\n6/10 - 60.00%\n[train] loss: 0.2875, acc: 91.38\n[test] loss: 0.7467, acc: 75.17\n100%|===========================================| 48/48 [00:25<00:00,  1.90it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.91it/s]\n              precision    recall  f1-score   support\n\n           0       0.99      0.84      0.91       205\n           1       0.88      0.80      0.84       159\n           2       0.78      0.97      0.87       211\n           3       0.55      0.69      0.61       174\n           4       0.68      0.56      0.61       270\n\n    accuracy                           0.76      1019\n   macro avg       0.78      0.77      0.77      1019\nweighted avg       0.77      0.76      0.76      1019\n\nBETTER MODEL SAVED\n7/10 - 70.00%\n[train] loss: 0.2599, acc: 92.17\n[test] loss: 0.7535, acc: 75.96\n100%|===========================================| 48/48 [00:25<00:00,  1.90it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.70it/s]\n              precision    recall  f1-score   support\n\n           0       0.99      0.84      0.91       205\n           1       0.85      0.81      0.83       159\n           2       0.79      0.96      0.87       211\n           3       0.54      0.68      0.61       174\n           4       0.68      0.54      0.60       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.77      0.76      1019\nweighted avg       0.77      0.76      0.76      1019\n\n8/10 - 80.00%\n[train] loss: 0.2424, acc: 92.82\n[test] loss: 0.7594, acc: 75.56\n100%|===========================================| 48/48 [00:24<00:00,  1.92it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.82it/s]\n              precision    recall  f1-score   support\n\n           0       0.99      0.84      0.91       205\n           1       0.85      0.81      0.83       159\n           2       0.80      0.96      0.87       211\n           3       0.55      0.70      0.61       174\n           4       0.68      0.56      0.61       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.77      0.77      1019\nweighted avg       0.77      0.76      0.76      1019\n\n9/10 - 90.00%\n[train] loss: 0.2213, acc: 93.86\n[test] loss: 0.7634, acc: 75.96\n100%|===========================================| 48/48 [00:24<00:00,  1.98it/s]\n100%|===========================================| 16/16 [00:05<00:00,  2.76it/s]\n              precision    recall  f1-score   support\n\n           0       0.99      0.84      0.91       205\n           1       0.85      0.81      0.83       159\n           2       0.79      0.96      0.87       211\n           3       0.55      0.69      0.61       174\n           4       0.68      0.56      0.61       270\n\n    accuracy                           0.76      1019\n   macro avg       0.77      0.77      0.77      1019\nweighted avg       0.77      0.76      0.76      1019\n\n10/10 - 100.00%\n[train] loss: 0.2236, acc: 93.67\n[test] loss: 0.7674, acc: 75.86\nbest loss: 0.7535, best acc: 75.96\nlog saved: sensitive_bert_ce_23-02-10_10-28-02.log\n","output_type":"stream"}]},{"cell_type":"code","source":"!python infer.py --dataset sensitive --method ce --lr 5e-6  --model_name bert --num_epoch 10 --alpha 0.5 --train_batch_size 32","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:33:27.540572Z","iopub.execute_input":"2023-02-10T10:33:27.540910Z","iopub.status.idle":"2023-02-10T10:33:42.321144Z","shell.execute_reply.started":"2023-02-10T10:33:27.540877Z","shell.execute_reply":"2023-02-10T10:33:42.319436Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"{0: 'insult', 1: 'religion', 2: 'terrorism', 3: 'politics', 4: 'neutral'}\n/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nPREDICTION (['neutral'], tensor([[ 1.9683, -1.3215, -0.7645, -1.9258,  1.9963]], device='cuda:0',\n       grad_fn=<AddmmBackward0>))\n","output_type":"stream"}]},{"cell_type":"code","source":"!python bot.py --dataset sensitive --method ce --lr 5e-6  --model_name bert --num_epoch 15 --alpha 0.5 --train_batch_size 32","metadata":{"execution":{"iopub.status.busy":"2023-02-03T16:38:08.937737Z","iopub.execute_input":"2023-02-03T16:38:08.938161Z","iopub.status.idle":"2023-02-03T16:43:04.710684Z","shell.execute_reply.started":"2023-02-03T16:38:08.938122Z","shell.execute_reply":"2023-02-03T16:43:04.709455Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSIGNAL tensor([[ 0.3487, -0.6063, -0.7915, -1.5538,  3.2496],\n        [ 3.3165, -1.3788, -1.4044, -1.6758,  1.2674]], device='cuda:0',\n       grad_fn=<AddmmBackward0>)\nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSIGNAL tensor([[-0.5726, -1.7051, -0.1553,  4.1291, -1.0607],\n        [-0.3017, -0.6017, -0.4248, -0.7035,  2.3198],\n        [-1.0584, -1.5119, -0.7603,  4.3316, -1.0096],\n        [-1.1958, -1.5059, -1.4639,  2.2415,  1.0579]], device='cuda:0',\n       grad_fn=<AddmmBackward0>)\n^C\n2023-02-03 16:43:04,101 (__init__.py:966 MainThread) ERROR - TeleBot: \"Infinity polling: polling exited\"\nInfinity polling: polling exited\n2023-02-03 16:43:04,102 (__init__.py:968 MainThread) ERROR - TeleBot: \"Break infinity polling\"\nBreak infinity polling\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}